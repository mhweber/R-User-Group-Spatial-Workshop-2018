---
title: Spatial Operations 1
---

## Lesson Goals

* Familiarity with topological operations (spatial subsetting, aggregation, buffering, spatial joins) using `sf`
* Learn how `sf` and `dplyr` work together
* Become familiar with typical raster operations using the `raster` package and combining with `vector` data

### Spatial Subsetting
Let's return to the Durham Open Data we grabbed in the previous section - the parks and trails layers in particular.  A typical spatial question we might ask of the data is 'what trails go through parks in town?' You should already have loaded but code below loads again, and shows the simplest of all methods to perform this spatial subset using `sf`:
```{r subset, message=FALSE, warning=FALSE, error=FALSE}
library(sf)
trails <- read_sf("https://opendurham.nc.gov/api/v2/catalog/datasets/existing-trails/exports/geojson")
parks <- read_sf("https://opendurham.nc.gov/api/v2/catalog/datasets/city-parks/exports/geojson")
plot(trails$geometry, col='green', axes=T)
plot(parks$geometry, col='blue', add=T)
trails_in_parks <- trails[parks,]
plot(trails_in_parks$geometry, col='red', lwd = 2, add=T)
title(main='Parks and Trails in Durham')
```

Notice the warning we got about planar coordinates - should we be concerned about that?

### Proximity calculation

Here's a gist I have of a function I've used based on `gDistance` in `geos` package working with `sp` points and polygons - we'll try to implement something similar in `sf`:
<script src="https://gist.github.com/mhweber/d87c3fdf9f71ac4f9e69565086ece74f.js"></script> 

Let's grab a geojson of bike parking locations from Durham Open Data, and then let's try to find and map all the bike parking that is within a half-mile of a park - in code below I test and try and few things and use some techniques you may have questions about. See if this all makes sense, we'll talk through, ask questions and we can discuss:
```{r bike_parking, message=FALSE, warning=FALSE, error=FALSE, eval = FALSE}
library(dplyr)
bike_parking <- read_sf("https://opendurham.nc.gov/api/v2/catalog/datasets/durham-bike-parking/exports/geojson")
bike_parking <- st_transform(bike_parking, crs=26917)
parks <- st_transform(parks, crs=26917)
sel <- st_is_within_distance(bike_parking, parks, dist = 804) # conversion of miles to meters - why am I using meters here?
summary(lengths(sel) > 0) 
# This is obviously not correct if we were to look at the features in ArcMap - there are numerous bike parking stations more than a mile from parks - something is wrong here....

# Let's try a different approach...perhaps I'm not understanding using the built in approach above, but here's how I got it to work
dist_mat <- st_distance(bike_parking, parks) # this creates a distance matrix of distances between each bike parking station and each park
dist_mat <- as.data.frame(dist_mat) # make it a data frame for manipulation 
# run the head statement below - why do I have 'as.data.frame' in here?
head(as.data.frame(bike_parking))
# Do you notice something strance about all the distance values in the matrix we produced?
dist_mat <- mutate_all(dist_mat, function(x) as.numeric(x)) # we use mutate_all from dplyr to convert everything in data frame to actual numeric values
dist_mat$min <- apply(X=dist_mat, MARGIN=1, FUN=min) # use apply function to generate new minimum distance column

any(dist_mat$min >0) # Still showing me there are no bike parking stations more than a half-mile from parks, which I know is not true from mapping the data
# solution is that there is a park record with corrupt geometry - park with 'objectid' 28 - it's distance is zero to every bike station!
# once we remove this record, the simple solution works just fine
```

The code chunk above identified a problem in the data - below we deal with it and use the simplest method in `sf` to plot our proximity results:
```{r bike_parking2, message=FALSE, warning=FALSE, error=FALSE}
library(ggplot2)
bike_parking <- read_sf("https://opendurham.nc.gov/api/v2/catalog/datasets/durham-bike-parking/exports/geojson")
bike_parking <- st_transform(bike_parking, crs=26917)
parks <- st_transform(parks, crs=26917)
parks <- parks[!parks$objectid==28,]
sel <- st_is_within_distance(bike_parking, parks, dist = 804) # just generating a distance matrix again to double-check
summary(lengths(sel) > 0) 
# That looks more like it! And I verified in desktop GIS that this is the correct answer
# Now it's simple to pull out what we want...
bike_parking_near_parks <- bike_parking[parks, ,op = st_is_within_distance, dist = 804]
ggplot() + 
  # geom_sf(data=parks, fill = "green", color="green") +
  geom_sf(data=bike_parking_near_parks, fill = "red", show.legend = F, color="red") +
  labs(title="Bike Parking Near Parks in Durham") +
  theme_bw()
```

### Using `sf` and `dplyr` together
It took a bit of a detour to figure out but we got our proximity question solved - now say I'm concerned it might rain.  I want to know where the covered bike parking is that is near parks and along trails.  Given what we know so far, see if you can figure out how to subset the bike parking near parks within 100 meters of trails and that is covered (attribute in the attribute table) and try using dplyr as well.
```{r bike_parking3, message=FALSE, warning=FALSE, error=FALSE}
trails <- st_transform(trails, crs=st_crs(parks))
bike_parking_near_parks_and_trails <- bike_parking_near_parks[trails, ,op = st_is_within_distance, dist = 100]
# dplyr chained operation
covered_bike_parking_near_parks_and_trails <- bike_parking_near_parks_and_trails %>%
  dplyr::filter(covered == 'yes')

ggplot() + 
  geom_sf(data=trails, color="green") +
  geom_sf(data=covered_bike_parking_near_parks_and_trails, fill = "red", show.legend = F, color="red") +
  labs(title="Covered Bike Parking Near Parks \nAlong Trails in Durham") +
  theme_bw()
```

### Spatial Joining and Aggregating
Let's grab a couple more sample data sets from Open Data Durham. Let's use EnviroAtlas data and schools, and we'll join schols to EnviroAtlas to determine percent population below poverty for the block group each school lands in using a spatial join.  
```{r schools_envatlas, message=FALSE, warning=FALSE, error=FALSE}
library(dplyr)
library(ggplot2)
enviroatlas <- read_sf("https://opendurham.nc.gov/api/v2/catalog/datasets/enviroatlas/exports/geojson")
public_schools <- read_sf("https://opendurham.nc.gov/api/v2/catalog/datasets/public-schools/exports/geojson")
# We want non-public schools too, but this is only available as tabular files, not geojson or shapefile:
non_public_schools <- read.csv("https://opendurham.nc.gov/api/v2/catalog/datasets/non-public-schools-in-durham-county-by-type/exports/csv", sep=';')
# Review - how do we promote to spaitial data? NOTE: the csv we read in they recorded latitude and longitude backwards, we fix below
non_public_schools  <- st_as_sf(non_public_schools , coords = c("lat", "long"), crs = 4326) # The order should be long then lat, but they recorded it wrong!
# what is crs of public_schools?
st_crs(public_schools)
# verify both are equal:
st_crs(public_schools) == st_crs(non_public_schools)
# We want to combine these two schools data frmaes and preserve school type-
public_schools$Type <- 'Public'
public_schools <- public_schools[c(14,13)]
non_public_schools$Type <- 'Non-Public'
non_public_schools <- non_public_schools[c(17,16)]
schools <- rbind(public_schools, non_public_schools)
ggplot() + 
  geom_sf(data=schools, aes(col=Type)) +
  geom_sf(data=enviroatlas , fill = NA, show.legend = F, color="black") +
  labs(title="Schools in Durham and \nCensus Block Groups") +
  theme_bw()

schools <- st_join(schools, enviroatlas) # st_intersects is the defaout
schools %>%
  group_by(Type) %>%
  dplyr::summarize(PercTwicePov = mean(percent_population_with_income_below_twice_the_poverty_level, na.rm = TRUE)) %>%
  ggplot(aes(x=Type, y=PercTwicePov, fill=Type)) + geom_bar(stat="identity") 
```

If we have time, try exploring another data set from Open Data Durham, or using existing data to put together another spatial subset, join, or aggregation.


